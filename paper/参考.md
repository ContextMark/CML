

[MLLM 提示的未来是自适应的：用于稳健多模态性能的提示工程方法的全面实验评估](https://arxiv.org/html/2504.10179v1)





~~[[2504.08778\] 从标记到格子：语言模型中的新兴格结构](https://arxiv.org/abs/2504.08778)~~



[VADIS：用于动态文档表示和信息搜索的可视化分析管道](https://arxiv.org/html/2504.05697v1)



[ONNX | Home](https://onnx.ai/)

[JSON](https://www.json.org/)

[JSON lines](https://jsonlines.org/)

[RDF - Semantic Web Standards](https://www.w3.org/RDF/)

[YAML](https://yaml.org/)

[Base58](https://zh.wikipedia.org/wiki/Base58)



[Context models and out-of-context objects](https://doi.org/10.1016/j.patrec.2011.12.004)

[The context model: An integrating view of vagueness and uncertainty](https://doi.org/10.1016/0888-613X(93)90014-5)

[Metadata Interoperability and Standardization](https://webdoc.sub.gwdg.de/edoc/aw/d-lib/dlib/june06/chan/06chan.html)

[Accounting for Context in Markup: Which Situation, Whose Semantics?](https://www.balisage.net/Proceedings/vol15/html/Wickett01/BalisageVol15-Wickett01.html)

[Natural Language Processing to Extract Contextual Structure from Requirements](https://doi.org/10.1109/SysCon53536.2022.9773855)

[Systematic review of the “semantic network” definitions](https://doi.org/10.1016/j.eswa.2022.118455)

在语义范式方面，最前沿的思考是这两篇。

由牛凯等人于2022年提出，旨在推动通信系统从传统香农范式下的的"语法层"向"语义层"转变，从"数据压缩"到"语义压缩"的转变，开启语义通信的新范式。并且在这个基础逻辑上，进一步提供了一种数学理论。

[ Towards Semantic Communications: A Paradigm Shift](https://arxiv.org/abs/2203.06692)

[A Mathematical Theory of Semantic Communication](https://doi.org/10.48550/arXiv.2401.14160)

在自然语言相关的元语言结构研究方面，崔希亮教授发表于《语言教学与研究》2002年第5期的文章，提供有一些认知模型，但这种模型维度是逻辑性的，而非结构性的。

[认知语言学:研究范围和研究方法 ](https://fls.blcu.edu.cn/attach/0/1410161054566649318.pdf)



在LLM的可解释性方面（解释 LLM 和使用 LLM 进行解释），源于当前LLM逻辑架构所带来的问题，行业已有不少反思。其中微软研究院的 Chandan Singh 等人与2024年1月撰写《重新思考大型语言模型时代的可解释性》，关注到了用于知识发现的数据集说明、可解释等概念，与本文设计思想背后的场景考量比较契合。

[Rethinking Interpretability in the Era of Large Language Models](https://doi.org/10.48550/arXiv.2402.01761)





[Some thoughts on the semantic structure of the sentence](https://doi.org/10.1016/0024-3841(68)90038-7)

[Representing logical and semantic structure of knowledge acquired from discourse](https://doi.org/10.1016/0010-0285(75)90016-X)

在语义生命周期方面，只有2009年Felix Modritscher写过一篇论文，提出对有意义数据的建模、应用程序、创作、挖掘和评估，但彼时的语义概念，跟LLM时代的语义概念完全不同。

[Semantic lifecycles: modelling, application, authoring, mining, and evaluation of meaningful data](https://doi.org/10.1504/IJKWI.2009.027928)



而跟语义建模相关的工具，比较主流的是以schema.org代表的词汇表，主要是面向搜索时代，而非LLM智能时代。另一个比较典型的是GoodData，他虽然是一个商业智能（BI）平台，但它在数据建模方面相比schema.org做了进一步的“语义层再抽象”，但GoodData 的核心机制依然是依赖预先定义的静态结构，没有范式变化。

在语义表达范式方面，以schema.org代表的词汇表，主要是面向搜索时代，而非LLM智能时代。

[One schema to rule them all: How Schema.org models the world of search](https://doi.org/10.1002/asi.24744)

[Semantic data model - Wikipedia](https://en.wikipedia.org/wiki/Semantic_data_model)



在知识治理架构和动态更新方面，RAG是一个主流方向，提供了动态检索知识的范式。另一个，中国浙江大学计算机学院的陈华军，在2023年提出了知识图谱和LLM融合的大知识模型概念，虽然方向不同，也同样表达了对“知识原文、语义结构、参数表示”进行解耦、分工、协作的架构性思考。但如果是借助RAG，还是知识图谱，传统方案的范式都存在语义冻结问题，只是形式不同。也有人设想了选择性推理的方向，

[Large Knowledge Model: Perspectives and Challenges](https://doi.org/10.48550/arXiv.2312.02706)

[Retrieval-augmented generation - Wikipedia](https://en.wikipedia.org/wiki/Retrieval-augmented_generation)

[Knowledge Updating? No More Model Editing! Just Selective Contextual Reasoning](https://doi.org/10.48550/arXiv.2503.05212)

多模态语义数据共享，虽然没有一个主流的方案，但被广泛关注。

[A Unified Multi-Task Semantic Communication System for Multimodal Data | IEEE Journals & Magazine | IEEE Xplore](https://ieeexplore.ieee.org/abstract/document/10431795)

[ShareGPT4V: Improving Large Multi-modal Models with Better Captions](https://sharegpt4v.github.io/)









[AR 中的对象驱动叙事：集成了 VLM 的场景隐喻框架](https://arxiv.org/html/2504.13119v1)

这个摸到一点门道了